{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle2",
      "provenance": [],
      "authorship_tag": "ABX9TyNncIHXiH5ghyCr8sD+V0la",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samibahig/IFT6390/blob/main/kaggle2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjer_hMQrG9S"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.sparse as sp \n",
        "import pandas as pd \n",
        "# import sklearn.utils.extmath.safe_sparse_dot\n",
        "import gc\n",
        "import re, unicodedata\n",
        "import string\n",
        "import tqdm\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLYcRDD9rsns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "1ff6563f-9939-40ce-b222-9e9e7b3211db"
      },
      "source": [
        "train, test = pd.read_csv('/content/train.csv'), pd.read_csv('/content/test.csv')\n",
        "print (train, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6a3f2fe9becb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7EwWkHpuxV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "64bfa9a5-08b5-48d9-d182-336728d6558c"
      },
      "source": [
        "print(train.keys())\n",
        "\n",
        "print(train['Abstract'])\n",
        "\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Id', 'Abstract', 'Category'], dtype='object')\n",
            "0         The energy released in a solar flare is part...\n",
            "1         In light of current atmospheric neutrino osc...\n",
            "2         We consider the following basic learning tas...\n",
            "3         In this paper, we characterise the family of...\n",
            "4         The control of condensed matter systems out ...\n",
            "                              ...                        \n",
            "7495      We investigate the dynamical behaviour of a ...\n",
            "7496      We use the full bispectrum of spherical need...\n",
            "7497      We show that Ostrogradsky ghosts in higher-d...\n",
            "7498      McMorris and Powers proved an Arrow-type the...\n",
            "7499      Recently it has been speculated that the War...\n",
            "Name: Abstract, Length: 7500, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The energy released in a solar flare is part...</td>\n",
              "      <td>astro-ph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>In light of current atmospheric neutrino osc...</td>\n",
              "      <td>hep-ph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>We consider the following basic learning tas...</td>\n",
              "      <td>cs.LG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>In this paper, we characterise the family of...</td>\n",
              "      <td>math.CO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The control of condensed matter systems out ...</td>\n",
              "      <td>cond-mat.mes-hall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7495</th>\n",
              "      <td>7495</td>\n",
              "      <td>We investigate the dynamical behaviour of a ...</td>\n",
              "      <td>astro-ph.CO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7496</th>\n",
              "      <td>7496</td>\n",
              "      <td>We use the full bispectrum of spherical need...</td>\n",
              "      <td>astro-ph.CO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7497</th>\n",
              "      <td>7497</td>\n",
              "      <td>We show that Ostrogradsky ghosts in higher-d...</td>\n",
              "      <td>hep-th</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7498</th>\n",
              "      <td>7498</td>\n",
              "      <td>McMorris and Powers proved an Arrow-type the...</td>\n",
              "      <td>math.CO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7499</th>\n",
              "      <td>7499</td>\n",
              "      <td>Recently it has been speculated that the War...</td>\n",
              "      <td>hep-th</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7500 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  ...           Category\n",
              "0        0  ...           astro-ph\n",
              "1        1  ...             hep-ph\n",
              "2        2  ...              cs.LG\n",
              "3        3  ...            math.CO\n",
              "4        4  ...  cond-mat.mes-hall\n",
              "...    ...  ...                ...\n",
              "7495  7495  ...        astro-ph.CO\n",
              "7496  7496  ...        astro-ph.CO\n",
              "7497  7497  ...             hep-th\n",
              "7498  7498  ...            math.CO\n",
              "7499  7499  ...             hep-th\n",
              "\n",
              "[7500 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odu9OU5PsK62"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    pass\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    pass\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "        return ''.join(new_words)\n",
        "def process(df, t):\n",
        "    df[t] = df[t].apply(lambda x : x.lower())\n",
        "    #train['Abstract'] = train['Abstract'].apply(lambda x : remove_punctuation(x))\n",
        "    df[t] = df[t].apply(lambda x : x.strip())\n",
        "    df[t] = df[t].apply(lambda x : re.sub('\\n', ' ', x))\n",
        "    df[t] = df[t].apply(lambda x : re.sub('\\[[^]]*\\]', '', x))\n",
        "    df[t] = df[t].apply(lambda x : re.sub(\"<.*?>\", \" \", x))\n",
        "    df[t] = df[t].apply(lambda x : remove_non_ascii(x))\n",
        "    df[t] = df[t].str.replace('[^\\w\\s]','')\n",
        "    print(df.head())\n",
        "    return df\n",
        "    #train['Abstract'] = train['Abstract'].apply(lambda x: remove_punctuation(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWRperWvsQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "f496e9c3-5dd2-44f6-daa6-341ace361220"
      },
      "source": [
        "t = train['Abstract']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         The energy released in a solar flare is part...\n",
            "1         In light of current atmospheric neutrino osc...\n",
            "2         We consider the following basic learning tas...\n",
            "3         In this paper, we characterise the family of...\n",
            "4         The control of condensed matter systems out ...\n",
            "                              ...                        \n",
            "7495      We investigate the dynamical behaviour of a ...\n",
            "7496      We use the full bispectrum of spherical need...\n",
            "7497      We show that Ostrogradsky ghosts in higher-d...\n",
            "7498      McMorris and Powers proved an Arrow-type the...\n",
            "7499      Recently it has been speculated that the War...\n",
            "Name: Abstract, Length: 7500, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO2HgXXttMfp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "b0ce1ea5-227c-4327-ffcb-0316208cba99"
      },
      "source": [
        "train = process(train, 'Abstract')\n",
        "test = process(test, 'Abstract')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Id Abstract           Category\n",
            "0   0        t           astro-ph\n",
            "1   1        i             hep-ph\n",
            "2   2        w              cs.LG\n",
            "3   3        i            math.CO\n",
            "4   4        t  cond-mat.mes-hall\n",
            "   Id Abstract\n",
            "0   0        w\n",
            "1   1        t\n",
            "2   2        o\n",
            "3   3        g\n",
            "4   4        t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pky4AjuBtSIU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "16d35de2-4217-49df-b6d6-df3e9a252260"
      },
      "source": [
        "class BernoulliVectorizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = []\n",
        "        self.vocab_counter = {}\n",
        "    def build_vocab(self, data):\n",
        "        for document in data:\n",
        "            for word in document.split(' '):\n",
        "                if word in self.vocab:\n",
        "                    self.vocab_counter[word] += 1\n",
        "                else:\n",
        "                    self.vocab.append(word)\n",
        "                    self.vocab_counter = 1\n",
        "    def transform(self, data):\n",
        "        i = 0 \n",
        "        for document in data:\n",
        "            tokens = document.split(' ')  # [ 'my', 'name', 'is', 'kasper', 'and', 'i', 'like', 'ml']\n",
        "                                          # ['my', 'kasper', 'hello']\n",
        "            bin_vect = np.zeros(len(self.vocab))\n",
        "            for word_idx in range(len(self.vocab)):\n",
        "                for e in tokens: \n",
        "                    if e == self.vocab[word_idx]:\n",
        "                        bin_vect[word_idx ] = 1\n",
        "                data[i] = bin_vect\n",
        "                i += 1\n",
        "        return data\n",
        "    \n",
        "    def fit_transform(self, data):\n",
        "        self.build_vocab(data)\n",
        "        return transform(data)\n",
        "\n",
        "B = BernoulliVectorizer()\n",
        "train['Abstract'] = B.fit_transform(train['Abstract'])\n",
        "test['Abstract'] = B.transform(test['Abstract'])\n",
        "train.head()\n",
        "train, test = train.to_numpy(), test.to_numpy()\n",
        "\n",
        "class BernoulliNB:\n",
        "    def __init__(self, alpha):\n",
        "        self.alpha = alpha\n",
        "        pass\n",
        "    '''P(C_k) =  number of documents of that class / number of documents\n",
        "       P(C_k / w1, w2, ...)\\prop P(C_k) P(w1/C_k) P(w2/ C_k)\n",
        "       P(wi / C_k) = number of documents of class C_k with w_i/ number of documents with that class \n",
        "       get all the rows of class C_k, how many of them was word w_i \n",
        "       get all the rows of class C_k, how many of them has a 1 in the index of w_i '''\n",
        "    def fit(self, X, y):\n",
        "        self.n_classes = len(np.unique(y))\n",
        "        n_classes = self.n_classes\n",
        "        self.counts = np.zeros(n_classes)\n",
        "        self.counts = np.zeros(n_classes)\n",
        "        for i in y:\n",
        "            self.counts[i] += 1,\n",
        "        self.counts /= len(y)\n",
        "     # generate n_features x n_classes matrix\\n\",   \n",
        "        self.params = np.zeros((n_classes, X.shape[1])),\n",
        "        for idx in range(len(X)):\n",
        "            self.params[y[idx]] += X[idx]\n",
        "        self.params += self.alpha \n",
        "        class_sums = self.params.sum(axis=1) + self.alpha * self.n_classes\n",
        "        self.params = self.params / class_sums[:, np.newaxis]\n",
        "    def predict(self, X): \n",
        "        neg_prob = np.log(1 - self.params)\n",
        "        jll = np.dot(X, (np.log(self.params)-neg_prob).T)           \n",
        "        jll += np.log(self.counts) + neg_prob.sum(axis=1)\n",
        "        return np.argmax(jll, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-054a26381af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulliVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    }
  ]
}