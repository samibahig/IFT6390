{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUSFUTV7kb2vjIyPE+YbKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samibahig/IFT6390/blob/main/kaggle2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjer_hMQrG9S"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.sparse as sp \n",
        "import pandas as pd \n",
        "# import sklearn.utils.extmath.safe_sparse_dot\n",
        "import gc\n",
        "import re, unicodedata\n",
        "import string\n",
        "import tqdm\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLYcRDD9rsns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "7cee697c-4447-4977-ddf3-942e8e508f98"
      },
      "source": [
        "train, test = pd.read_csv('/content/train.csv'), pd.read_csv('/content/test.csv')\n",
        "print (train, test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Id  ...           Category\n",
            "0        0  ...           astro-ph\n",
            "1        1  ...             hep-ph\n",
            "2        2  ...              cs.LG\n",
            "3        3  ...            math.CO\n",
            "4        4  ...  cond-mat.mes-hall\n",
            "...    ...  ...                ...\n",
            "7495  7495  ...        astro-ph.CO\n",
            "7496  7496  ...        astro-ph.CO\n",
            "7497  7497  ...             hep-th\n",
            "7498  7498  ...            math.CO\n",
            "7499  7499  ...             hep-th\n",
            "\n",
            "[7500 rows x 3 columns]           Id                                           Abstract\n",
            "0          0    We describe ways to define and calculate $L_...\n",
            "1          1    The progenitor systems of Type-Ia supernovae...\n",
            "2          2    OmegaWhite is a wide-field, high cadence, sy...\n",
            "3          3    Given $n \\geq 2$ and $1<p<n$, we consider th...\n",
            "4          4    The motivation of this work is to improve th...\n",
            "...      ...                                                ...\n",
            "14995  14995    We investigate the ability of the Space Infr...\n",
            "14996  14996    We study theoretically the influence of the ...\n",
            "14997  14997    We present multifrequency radio observations...\n",
            "14998  14998    It is commonly accepted that the combination...\n",
            "14999  14999    The coherent optical manipulation of solids ...\n",
            "\n",
            "[15000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7EwWkHpuxV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b5bea37a-dcac-4606-f7bb-d4ab51a2dd1f"
      },
      "source": [
        "# print(train.keys())\n",
        "\n",
        "print(train['Abstract'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         The energy released in a solar flare is part...\n",
            "1         In light of current atmospheric neutrino osc...\n",
            "2         We consider the following basic learning tas...\n",
            "3         In this paper, we characterise the family of...\n",
            "4         The control of condensed matter systems out ...\n",
            "                              ...                        \n",
            "7495      We investigate the dynamical behaviour of a ...\n",
            "7496      We use the full bispectrum of spherical need...\n",
            "7497      We show that Ostrogradsky ghosts in higher-d...\n",
            "7498      McMorris and Powers proved an Arrow-type the...\n",
            "7499      Recently it has been speculated that the War...\n",
            "Name: Abstract, Length: 7500, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsv3s8gVO0nU"
      },
      "source": [
        "def remove_non_ascii(words):\n",
        "    return ''.join([i if ord(i) < 128 else ' ' for i in words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgYNCvDgO3TZ"
      },
      "source": [
        "def process(df, t):\n",
        "    df[t] = df[t].apply(lambda x : x.lower())\n",
        "    #train['Abstract'] = train['Abstract'].apply(lambda x : remove_punctuation(x))\n",
        "    df[t] = df[t].apply(lambda x : x.strip())\n",
        "    df[t] = df[t].apply(lambda x : re.sub('\\n', ' ', x))\n",
        "    df[t] = df[t].apply(lambda x : re.sub('\\[[^]]*\\]', '', x))\n",
        "    df[t] = df[t].apply(lambda x : re.sub(\"<.*?>\", \" \", x))\n",
        "    df[t] = df[t].apply(lambda x : remove_non_ascii(x))\n",
        "    df[t] = df[t].str.replace('[^\\w\\s]','')\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVR-JQpNO53Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb8d89f1-fe3d-485a-9e5e-e473b8a50a2c"
      },
      "source": [
        "t = train['Abstract']\n",
        "\n",
        "train = process(train, 'Abstract')\n",
        "test = process(test, 'Abstract')\n",
        "\n",
        "train['Abstract']\n",
        "print(train['Abstract'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdW06U8OO83S"
      },
      "source": [
        "class BernoulliVectorizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = []\n",
        "        self.vocab_counter = {}\n",
        "    def build_vocab(self, data):\n",
        "        for document in data:\n",
        "            for word in document.split(' '):\n",
        "                if word in self.vocab_counter:\n",
        "                    self.vocab_counter[word] += 1\n",
        "                    if self.vocab_counter[word] == 2:\n",
        "                        self.vocab.append(word)\n",
        "                else:\n",
        "                    self.vocab_counter[word] = 1\n",
        "    def transform(self, data):\n",
        "        i = 0\n",
        "        counter = 0 \n",
        "        answer = np.zeros((len(data),len(self.vocab)))\n",
        "        for document in data:\n",
        "            counter = counter + 1\n",
        "            token = document.split(' ')                                 \n",
        "            bin_vect = np.zeros(len(self.vocab))\n",
        "            for word_idx in range(len(self.vocab)):\n",
        "                for e in token: \n",
        "                    if e == self.vocab[word_idx]:\n",
        "                        bin_vect[word_idx ] = 1\n",
        "            answer[i, :] = bin_vect\n",
        "            i += 1\n",
        "        return answer\n",
        "    \n",
        "    def fit_transform(self, data):\n",
        "        self.build_vocab(data)\n",
        "        print(len(self.vocab))\n",
        "        return self.transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEWrTJDFO_0S"
      },
      "source": [
        "BV = BernoulliVectorizer()\n",
        "#X_train = BV.fit_transform(train['Abstract'])\n",
        "#test['Abstract'] = B.transform(test['Abstract'])\n",
        "# train.head()\n",
        "# train  = train.to_numpy() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8HMJhjBPCxZ"
      },
      "source": [
        "class BernoulliNB:\n",
        "    def __init__(self, alpha):\n",
        "        self.alpha = alpha   \n",
        "    '''P(C_k) =  number of documents of that class / number of documents\n",
        "       P(C_k / w1, w2, ...)\\prop P(C_k) P(w1/C_k) P(w2/ C_k)\n",
        "       P(wi / C_k) = number of documents of class C_k with w_i/ number of documents with that class \n",
        "       get all the rows of class C_k, how many of them was word w_i \n",
        "       get all the rows of class C_k, how many of them has a 1 in the index of w_i '''\n",
        "    def fit(self, X, y):\n",
        "        self.n_classes = len(np.unique(np.unique(y,return_inverse=True)[1]))\n",
        "        n_classes = self.n_classes\n",
        "        # calculate P(C_k) for all k\n",
        "        self.counts = np.zeros(n_classes)\n",
        "        y_cat = np.unique(y,return_inverse=True)[1]\n",
        "        for i in y_cat:\n",
        "            self.counts[i] += 1,\n",
        "        self.counts /= len(y_cat)\n",
        "     # generate n_features x n_classes matrix\\n\",   \n",
        "        self.params = np.zeros((n_classes, X.shape[1]))\n",
        "        for idx in range(len(X)):\n",
        "            self.params[y_cat[idx]] += X[idx]\n",
        "        self.params += self.alpha \n",
        "        class_sums = self.params.sum(axis=1) +  self.alpha * self.n_classes  #laplace\n",
        "        self.params = self.params / class_sums[:, np.newaxis]\n",
        "    def predict(self, X):\n",
        "        neg_prob = np.log(1 - self.params)\n",
        "        # compute neg_prob\n",
        "        jll = np.dot(X, (np.log(self.params)-neg_prob).T)           \n",
        "        jll += np.log(self.counts) + neg_prob.sum(axis=1)\n",
        "        return np.argmax(jll, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1e_MTyPHSq"
      },
      "source": [
        "uni, cats = np.unique(train['Category'],return_inverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwycwViqPIoC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3a1f1f7e-472e-4afd-c4cf-233c247c5cd7"
      },
      "source": [
        "alpha = 1\n",
        "NB = BernoulliNB(alpha)\n",
        "X_train = BV.fit_transform(train['Abstract'])\n",
        "NB.fit(X_train, train['Category'])\n",
        "print('Alhumdulillah')\n",
        "X_test = BV.transform(test['Abstract'])\n",
        "Y_test = NB.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21485\n",
            "Alhumdulillah\n",
            "Alhumdulillah\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4ZoCVbtJ3nY"
      },
      "source": [
        "Y_submit = uni[Y_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vlDog3JNlPE"
      },
      "source": [
        "Y_predict = NB.predict(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yZXuwFoMhSt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43acbaa2-6b1c-4ad4-b6e3-32603e6cc6fe"
      },
      "source": [
        "np.mean(cats == Y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9297333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCzCdyDSSNaU"
      },
      "source": [
        "pd.DataFrame(Y_submit).to_csv('Bernoulli21485.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odu9OU5PsK62"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    pass\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    return ''.join([i if ord(i) < 128 else ' ' for i in words])\n",
        "#    new_words = []\n",
        "#    for word in words:\n",
        "#        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "#        new_words.append(new_word)\n",
        "#        return ''.join(new_words)\n",
        "def process(df, t):\n",
        "    df[t] = df[t].apply(lambda x : x.lower())\n",
        "    #train['Abstract'] = train['Abstract'].apply(lambda x : remove_punctuation(x))\n",
        "    df[t] = df[t].apply(lambda x : x.strip())\n",
        "    df[t] = df[t].apply(lambda x : re.sub('\\n', ' ', x))\n",
        "    df[t] = df[t].apply(lambda x : re.sub('\\[[^]]*\\]', '', x))\n",
        "    df[t] = df[t].apply(lambda x : re.sub(\"<.*?>\", \" \", x))\n",
        "    df[t] = df[t].apply(lambda x : remove_non_ascii(x))\n",
        "    df[t] = df[t].str.replace('[^\\w\\s]','')\n",
        "    print(df.head())\n",
        "    return df\n",
        "    #train['Abstract'] = train['Abstract'].apply(lambda x: remove_punctuation(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTWRperWvsQp"
      },
      "source": [
        "Features_train = train['Abstract']\n",
        "Labels_train = train['Category']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO2HgXXttMfp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4ce55c0c-82d5-4531-d225-5cc5f5a391ed"
      },
      "source": [
        "train = process(train, 'Abstract')\n",
        "test = process(test, 'Abstract')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Id                                           Abstract           Category\n",
            "0   0  the energy released in a solar flare is partit...           astro-ph\n",
            "1   1  in light of current atmospheric neutrino oscil...             hep-ph\n",
            "2   2  we consider the following basic learning task ...              cs.LG\n",
            "3   3  in this paper we characterise the family of fi...            math.CO\n",
            "4   4  the control of condensed matter systems out of...  cond-mat.mes-hall\n",
            "   Id                                           Abstract\n",
            "0   0  we describe ways to define and calculate l_1no...\n",
            "1   1  the progenitor systems of typeia supernovae sn...\n",
            "2   2  omegawhite is a widefield high cadence synopti...\n",
            "3   3  given n geq 2 and 1pn we consider the critical...\n",
            "4   4  the motivation of this work is to improve the ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow_O230cUjL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d9a1581-7446-495e-d817-bde111c0947b"
      },
      "source": [
        "train['Abstract']\n",
        "print(train['Abstract'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pky4AjuBtSIU"
      },
      "source": [
        "class BernoulliVectorizer:\n",
        "    def __init__(self):\n",
        "        self.vocab = []\n",
        "        self.vocab_counter = {}\n",
        "    def build_vocab(self, data):\n",
        "        for document in data:\n",
        "            for word in document.split(' '):\n",
        "                if word in self.vocab_counter:\n",
        "                    self.vocab_counter[word] += 1\n",
        "                    if self.vocab_counter[word] == 500:\n",
        "                        self.vocab.append(word)\n",
        "                else:\n",
        "                    self.vocab_counter[word] = 1\n",
        "    def transform(self, data):\n",
        "        i = 0\n",
        "        #counter = 0 \n",
        "        answer = np.zeros((len(data),len(self.vocab)))\n",
        "        for document in data:\n",
        "            #counter = counter + 1\n",
        "            token = document.split(' ')                                 \n",
        "            bin_vect = np.zeros(len(self.vocab))\n",
        "            for word_idx in range(len(self.vocab)):\n",
        "                for e in token: \n",
        "                    if e == self.vocab[word_idx]:\n",
        "                        bin_vect[word_idx ] = 1\n",
        "            answer[i, :] = bin_vect\n",
        "            i += 1\n",
        "        return answer\n",
        "    \n",
        "    def fit_transform(self, data):\n",
        "        self.build_vocab(data)\n",
        "        print(len(self.vocab))\n",
        "        return self.transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og-z-HxLv5l0"
      },
      "source": [
        "class BernoulliNB:\n",
        "    def __init__(self, alpha):\n",
        "        self.alpha = alpha   \n",
        "    '''P(C_k) =  number of documents of that class / number of documents\n",
        "       P(C_k / w1, w2, ...)\\prop P(C_k) P(w1/C_k) P(w2/ C_k)\n",
        "       P(wi / C_k) = number of documents of class C_k with w_i/ number of documents with that class \n",
        "       get all the rows of class C_k, how many of them was word w_i \n",
        "       get all the rows of class C_k, how many of them has a 1 in the index of w_i '''\n",
        "    def fit(self, X, y):\n",
        "        self.n_classes = len(np.unique(y))\n",
        "        n_classes = self.n_classes\n",
        "        # calculate P(C_k) for all k)\n",
        "        y_cat = np.unique(y,return_inverse=True)[1]\n",
        "        self.counts = np.zeros(n_classes)\n",
        "        for i in y_cat:\n",
        "            self.counts[i] += 1,\n",
        "        self.counts /= len(y_cat)\n",
        "     # generate n_features x n_classes matrix\\n\",   \n",
        "        self.params = np.zeros((n_classes, X.shape[1])),\n",
        "        for idx in range(len(X)):\n",
        "            self.params[y_cat[idx]] += X[idx]\n",
        "        self.params += self.alpha \n",
        "        class_sums = self.params.sum(axis=1) +  self.alpha * self.n_classes  #laplace\n",
        "        self.params = self.params / class_sums[:, np.newaxis]\n",
        "    def predict(self, X):\n",
        "        neg_prob = np.log(1 - self.params)\n",
        "        # compute neg_prob\n",
        "        jll = np.dot(X, (np.log(self.params)-neg_prob).T)           \n",
        "        jll += np.log(self.counts) + neg_prob.sum(axis=1)\n",
        "        return np.argmax(jll, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBTF50hXwHtg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0ad06f6a-48a2-4ceb-a835-40bf07c69dc8"
      },
      "source": [
        "B = BernoulliVectorizer()\n",
        "alpha = 1\n",
        "NB = BernoulliNB(alpha)\n",
        "X_train = B.fit_transform(train['Abstract'])\n",
        "X_test = B.transform(test['Abstract'])\n",
        "NB.fit(X_train, train[\"Category\"])\n",
        "predictions = NB.predict(X_test)\n",
        "train_predictions= NB.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-de2b16959ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mNB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Category\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-94077735db25>\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-94077735db25>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                         \u001b[0mbin_vect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_idx\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbin_vect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}